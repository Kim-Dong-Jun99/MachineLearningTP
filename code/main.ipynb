{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Dataset imports\n",
    "import json\n",
    "\n",
    "# For restoring the dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "# Text manipulations\n",
    "import re\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cosine similarity\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# File download (Golve)\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library installation\n",
    "* NLTK - Natural Language toolkit\n",
    "* NetworkX - Structure, Dynamics, and Functions of complex networks Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.8.8)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install nltk\n",
    "!python -m pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK: Library for NLP Process\n",
    "* Usage:\n",
    "    * nltk.corpus.**stopwords**: stopwords of specific language\n",
    "    * nltk.tokenize.**RegexpTokenizer**: Tokenize the input sentences\n",
    "    * nltk.stem.**WordNetLemmatizer**: Lemmatize the word net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redial Parser\n",
    "A separated library for parsing the redial dataset\n",
    "\n",
    "class **RedialParser**\n",
    "- Restore(): Restore train, test, and movie dataset to initial state\n",
    "   * return:\n",
    "        * None\n",
    "- Movies(train): Get movie list in dataset\n",
    "   * param:\n",
    "        * train (bool): Target dataset, (train=True, test=False, all=None)\n",
    "   * return:\n",
    "        * dict: {index, MovieName}\n",
    "- describe(): Describe its datasets\n",
    "   * return:\n",
    "        * None\n",
    "- train: Train data of ReDial.\n",
    "- test: Test data of ReDial.\n",
    "- movie: Movie mention counts for ReDial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    TODO: initialization function for dataset reads\n",
    "\n",
    "        :arg\n",
    "            path (str): Dataset path.\n",
    "        :return\n",
    "            tuple: (train, test, df_mention)\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    for line in open(f\"{path}/train_data.jsonl\", \"r\"):\n",
    "        train_data.append(json.loads(line))\n",
    "\n",
    "    test_data = []\n",
    "    for line in open(f\"{path}/test_data.jsonl\", \"r\"):\n",
    "        test_data.append(json.loads(line))\n",
    "\n",
    "    mention_dataframe = pd.read_csv(f\"{path}/movies_with_mentions.csv\")\n",
    "\n",
    "    return train_data, test_data, mention_dataframe\n",
    "\n",
    "\n",
    "class RedialParser:\n",
    "    def __init__(self, path):\n",
    "        self.train, self.test, self.movie = load_data(path)\n",
    "\n",
    "        self._global_movie_list = None  # list of all movie names (global movie name data)\n",
    "        self._global_msg_list = None  # list of whole lines (global line data)\n",
    "        self._local_movie_list = None  # list of movie names (local movie name data)\n",
    "        self._local_msg_list = None  # list of lines (local line data)\n",
    "\n",
    "        self.dialog_df = None  # Sum of dialogs for each movie indices\n",
    "\n",
    "        self.__train = deepcopy(self.train)\n",
    "        self.__test = deepcopy(self.test)\n",
    "        self.__movie = deepcopy(self.movie)\n",
    "\n",
    "        self.__model = None\n",
    "\n",
    "\n",
    "    def Restore(self):\n",
    "        \"\"\"\n",
    "        TODO: Restore train, test, and movie dataset to initial state\n",
    "        \"\"\"\n",
    "        self.train = deepcopy(self.__train)\n",
    "        self.test = deepcopy(self.__test)\n",
    "        self.movie = deepcopy(self.__movie)\n",
    "\n",
    "\n",
    "    def Movies(self, train=True) -> dict:\n",
    "        \"\"\"\n",
    "        TODO: Get movie list in dataset\n",
    "\n",
    "            :arg\n",
    "                train (bool): Target dataset, (train=True, test=False, all=None)\n",
    "            :return\n",
    "                dict: {index, MovieName}\n",
    "        \"\"\"\n",
    "        if train is None:\n",
    "            result = self.Movies()\n",
    "            result.update(self.Movies(False))\n",
    "            return result\n",
    "\n",
    "        target = None\n",
    "        if train is True:\n",
    "            target = self.train\n",
    "        elif train is False:\n",
    "            target = self.test\n",
    "\n",
    "        result = {}\n",
    "\n",
    "        if target is not None:\n",
    "            for elem in target:\n",
    "                result.update(elem['movieMentions'])\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        TODO: Describe its datasets\n",
    "        \"\"\"\n",
    "        len1, len2 = len(self.train), len(self.test)\n",
    "        n1, n2 = 0, 0\n",
    "        m1, m2 = 0, 0\n",
    "\n",
    "        for e in self.train:\n",
    "            n1 += len(e['movieMentions'])\n",
    "            m1 += len(e['messages'])\n",
    "        for e in self.test:\n",
    "            n2 += len(e['movieMentions'])\n",
    "            m2 += len(e['messages'])\n",
    "\n",
    "        print('Brief information:\\n'\n",
    "              f'Length of train data: {len1}\\n'\n",
    "              f'Length of test data: {len2}\\n\\n'\n",
    "              'Data information:\\n'\n",
    "              f'Key parameters: {list(self.train[0].keys())}\\n'\n",
    "              f'Key parameters in Questions: {list(list(self.train[0][\"respondentQuestions\"].values())[0].keys())}\\n'\n",
    "              f'Key parameters in messages: {list(self.train[0][\"messages\"][0].keys())}\\n\\n'\n",
    "              'Context information:\\n'\n",
    "              f'Total mentioned movie number (train): {n1}\\n'\n",
    "              f'Total mentioned movie number in unique (train): {len(self.Movies())}\\n'\n",
    "              f'Total message number (train): {m1}\\n'\n",
    "              f'Total mentioned movie number (test): {n2}\\n'\n",
    "              f'Total mentioned movie number in unique (test): {len(self.Movies(False))}\\n'\n",
    "              f'Total message number (test): {m2}\\n'\n",
    "              f'Average mentioned movie numbers per conversation (train): {n1 / len1}\\n'\n",
    "              f'Average message numbers per conversation (train): {m1 / len1}\\n'\n",
    "              f'Average mentioned movie numbers per conversation (test): {n2 / len2}\\n'\n",
    "              f'Average message numbers per conversation (test): {m2 / len2}\\n\\n'\n",
    "              , end='')\n",
    "    \n",
    "\n",
    "    def preprocessing(self):\n",
    "        \"\"\"\n",
    "        TODO: Regroup train dataset into purposed structure and clean up data\n",
    "        \"\"\"\n",
    "        compile = re.compile(\"\\W+\")  # Format\n",
    "        \n",
    "        ran = range(len(self.train))\n",
    "\n",
    "        # initialize list\n",
    "        self._global_movie_list = []\n",
    "        self._global_msg_list = []\n",
    "        self._local_movie_list = [[] for _ in ran]\n",
    "        self._local_msg_list = [[] for _ in ran]\n",
    "\n",
    "        for i, data in enumerate(self.train):\n",
    "            for msg in data['messages']:  # append line to the lists\n",
    "                self._local_msg_list[i].append(msg['text'])\n",
    "                self._global_msg_list.append(msg['text'])\n",
    "\n",
    "            # Extract movie indices\n",
    "            for idx, line in enumerate(self._local_msg_list[i]):\n",
    "                numbers = re.findall(r'@\\d+', line)  # find number keywords (ex: @12345)\n",
    "                for number in numbers:\n",
    "                    self._local_movie_list[i].append(number[1:])\n",
    "                    self._global_movie_list.append(number[1:])\n",
    "\n",
    "                    # Remove index string\n",
    "                    pos = line.index(number)\n",
    "                    line = self._local_msg_list[i][idx] = line[0: pos] + line[pos + len(number): len(line)]\n",
    "\n",
    "                # Post: clear meaningless words\n",
    "                a = compile.sub(\" \", line)  # Clear special character\n",
    "                self._local_msg_list[i][idx] = a.lower()  # lower character\n",
    "\n",
    "        # Construct dialog dataframe\n",
    "        self.dialog_df = pd.DataFrame(columns=[\"movieid\", \"dialog\"])\n",
    "\n",
    "        for lines, movies in zip(self._local_msg_list, self._local_movie_list):\n",
    "            dig = ''\n",
    "            for line in lines:  # concatenate all sentences in related message dialog\n",
    "                dig += ' ' + str(line)\n",
    "            \n",
    "            for mv in movies:\n",
    "                if self.dialog_df[self.dialog_df['movieid'] == mv].empty:\n",
    "                    newrow = pd.DataFrame({'movieid': [mv], 'dialog': [dig]}, columns=self.dialog_df.columns)\n",
    "                    self.dialog_df = pd.concat([self.dialog_df, newrow], ignore_index=True)\n",
    "                else:\n",
    "                    target = self.dialog_df[self.dialog_df['movieid'] == mv].index[0]\n",
    "                    self.dialog_df.iloc[target, 1] = self.dialog_df.iloc[target, 1] + ' ' + dig\n",
    "        \n",
    "        # Drop NaN with empty sentence\n",
    "        self.dialog_df['dialog'].dropna(how='any', inplace=True)\n",
    "        \n",
    "\n",
    "    def get_frequency_matrix(self, tags):\n",
    "        \"\"\"\n",
    "        TODO: compute the frequency of tag words to obtain the TF-IDFs matrix\n",
    "\n",
    "            :arg\n",
    "                tags (list): list of key words.\n",
    "            :return\n",
    "                pandas.DataFrame: frequency matrix of tag words.\n",
    "        \"\"\"\n",
    "        stop_word_eng = set(stopwords.words('english'))\n",
    "        ran = range(len(self.train))\n",
    "\n",
    "        msg_list = deepcopy(self._local_msg_list)\n",
    "\n",
    "        for i in ran:\n",
    "            msg_list[i] = [j for j in msg_list[i] if j not in stop_word_eng]  # Clear stopwords\n",
    "\n",
    "        # Lemmatizer class\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = RegexpTokenizer('[\\w]+')\n",
    "\n",
    "        x = pd.DataFrame(columns=['id'] + tags)\n",
    "\n",
    "        for idx, msg in enumerate(msg_list):\n",
    "            result_pre_lem = [token.tokenize(j) for j in msg]\n",
    "            middle_pre_lem = [r for j in result_pre_lem for r in j]\n",
    "            final_lem = [lemmatizer.lemmatize(j) for j in middle_pre_lem if not j in stop_word_eng]  # Remove stopword\n",
    "\n",
    "            # Lemmatization\n",
    "            english = pd.Series(final_lem)\n",
    "            for word in english:\n",
    "                if word in tags:\n",
    "                    for movie in self._local_movie_list[idx]:\n",
    "                        if x[x['id'] == movie].empty:\n",
    "                            new_row = pd.DataFrame({'id': [movie]}, columns=x.columns)\n",
    "                            x = pd.concat([x, new_row], ignore_index=True)\n",
    "                            x.fillna(0, inplace=True)\n",
    "                        x.loc[x['id'] == movie, word] += 1\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def get_tfidf_matrix(self, **tfidf_keys):\n",
    "        \"\"\"\n",
    "        TODO: Compute TF-IDFs matrix\n",
    "\n",
    "            :arg\n",
    "                tfidf_keys(keyword dict): TfidfVectorizer parameters\n",
    "            :return\n",
    "                numpy.ndrarry: TF-IDFs matrix\n",
    "                numpy.ndarray: feature name of TF-IDFs (word)\n",
    "        \"\"\"\n",
    "        # Vectorizer class\n",
    "        tfidf = TfidfVectorizer(**tfidf_keys)  # Ignore English Stopwords\n",
    "\n",
    "        # Obtain matrix\n",
    "        tfidf_df = tfidf.fit_transform(self.dialog_df['dialog'])\n",
    "\n",
    "        return tfidf_df.toarray(), tfidf.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n",
    "Import dataset, describe it briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brief information:\n",
      "Length of train data: 10006\n",
      "Length of test data: 1342\n",
      "\n",
      "Data information:\n",
      "Key parameters: ['movieMentions', 'respondentQuestions', 'messages', 'conversationId', 'respondentWorkerId', 'initiatorWorkerId', 'initiatorQuestions']\n",
      "Key parameters in Questions: ['suggested', 'seen', 'liked']\n",
      "Key parameters in messages: ['timeOffset', 'text', 'senderWorkerId', 'messageId']\n",
      "\n",
      "Context information:\n",
      "Total mentioned movie number (train): 52918\n",
      "Total mentioned movie number in unique (train): 6223\n",
      "Total message number (train): 182150\n",
      "Total mentioned movie number (test): 7154\n",
      "Total mentioned movie number in unique (test): 2007\n",
      "Total message number (test): 23952\n",
      "Average mentioned movie numbers per conversation (train): 5.288626823905656\n",
      "Average message numbers per conversation (train): 18.20407755346792\n",
      "Average mentioned movie numbers per conversation (test): 5.330849478390462\n",
      "Average message numbers per conversation (test): 17.847988077496275\n",
      "\n",
      "length of train dataset: 10006\n"
     ]
    }
   ],
   "source": [
    "parser = RedialParser('../dataset')\n",
    "parser.describe()  # Describe read dataset\n",
    "\n",
    "# Size of train data\n",
    "num = len(parser.train)\n",
    "print(f'length of train dataset: {num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Clear the special character and extract the text and movie indices\n",
    "- example: \"I like animations like @84779 and @191602\" → [i like animations like  and ], [84779, 191602]\n",
    "\n",
    "\n",
    "Specific:\n",
    "* Transform dataset structure.\n",
    "    * Original: [movieMentions, {messages}, conversationId, ...]\n",
    "    * Transformed: [movie_indices], [message_contexts], [[1st_movie_index], [2nd_...], ...], [[1st_message_context], [2nd_...], ...]\n",
    "    * Dialog Dataframe (*self.dialog_df*): {'movie_id': '1st message' + '2nd message' + ...} - Used in generation of **TF-IDF** matrix\n",
    "* Recognize movie indices\n",
    "    * **@** recognition: use re library's *findall(@\\d+)* function, it only detects '@' + index strings.\n",
    "* Clean up meaningless values\n",
    "    * Special characters: use re library's format *\\w+*, it only receives widechar characters.\n",
    "    * Movie index: remove context of them by using text slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>dialog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84779</td>\n",
       "      <td>hi there how are you i m looking for movie re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191602</td>\n",
       "      <td>hi there how are you i m looking for movie re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122159</td>\n",
       "      <td>hi there how are you i m looking for movie re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165710</td>\n",
       "      <td>hi there how are you i m looking for movie re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151313</td>\n",
       "      <td>hi there how are you i m looking for movie re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>166377</td>\n",
       "      <td>hi hello there i like sci fi genetic modifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>205981</td>\n",
       "      <td>what kind of movies do you like  hello i am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>106113</td>\n",
       "      <td>hi hi i like sci fi movies genetic modificati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>96852</td>\n",
       "      <td>hi hi have a good day which kind of movie do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>200018</td>\n",
       "      <td>hello  hi how can i help you so some of the m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieid                                             dialog\n",
       "0      84779   hi there how are you i m looking for movie re...\n",
       "1     191602   hi there how are you i m looking for movie re...\n",
       "2     122159   hi there how are you i m looking for movie re...\n",
       "3     165710   hi there how are you i m looking for movie re...\n",
       "4     151313   hi there how are you i m looking for movie re...\n",
       "...      ...                                                ...\n",
       "6217  166377   hi hello there i like sci fi genetic modifica...\n",
       "6218  205981   what kind of movies do you like  hello i am l...\n",
       "6219  106113   hi hi i like sci fi movies genetic modificati...\n",
       "6220   96852   hi hi have a good day which kind of movie do ...\n",
       "6221  200018   hello  hi how can i help you so some of the m...\n",
       "\n",
       "[6222 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.preprocessing()\n",
    "parser.dialog_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "* 1. Extract words and their counts related to the movies. (Did not used, only for eye inspection.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedy</th>\n",
       "      <th>scary</th>\n",
       "      <th>love</th>\n",
       "      <th>animation</th>\n",
       "      <th>artistic</th>\n",
       "      <th>war</th>\n",
       "      <th>sci</th>\n",
       "      <th>blood</th>\n",
       "      <th>hero</th>\n",
       "      <th>romantic</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5101.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "      <td>5101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.840227</td>\n",
       "      <td>1.325230</td>\n",
       "      <td>7.919035</td>\n",
       "      <td>0.204666</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.583023</td>\n",
       "      <td>0.990982</td>\n",
       "      <td>0.059792</td>\n",
       "      <td>0.304058</td>\n",
       "      <td>1.089982</td>\n",
       "      <td>3.916095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.739531</td>\n",
       "      <td>10.106137</td>\n",
       "      <td>20.996916</td>\n",
       "      <td>1.584999</td>\n",
       "      <td>0.091594</td>\n",
       "      <td>4.267986</td>\n",
       "      <td>6.156864</td>\n",
       "      <td>0.447819</td>\n",
       "      <td>2.396133</td>\n",
       "      <td>6.209539</td>\n",
       "      <td>19.184717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>449.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>673.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            comedy        scary         love    animation     artistic  \\\n",
       "count  5101.000000  5101.000000  5101.000000  5101.000000  5101.000000   \n",
       "mean      5.840227     1.325230     7.919035     0.204666     0.006469   \n",
       "std      21.739531    10.106137    20.996916     1.584999     0.091594   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     2.000000     0.000000     0.000000   \n",
       "75%       3.000000     0.000000     6.000000     0.000000     0.000000   \n",
       "max     449.000000   494.000000   380.000000    64.000000     2.000000   \n",
       "\n",
       "               war          sci        blood         hero     romantic  \\\n",
       "count  5101.000000  5101.000000  5101.000000  5101.000000  5101.000000   \n",
       "mean      0.583023     0.990982     0.059792     0.304058     1.089982   \n",
       "std       4.267986     6.156864     0.447819     2.396133     6.209539   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max     175.000000   160.000000    15.000000    81.000000   153.000000   \n",
       "\n",
       "            action  \n",
       "count  5101.000000  \n",
       "mean      3.916095  \n",
       "std      19.184717  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       2.000000  \n",
       "max     673.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tag words words related with movie genres\n",
    "mv_tags = ['comedy','scary','love','animation','artistic','war','sci','blood','hero','romantic','action']\n",
    "frequency = parser.get_frequency_matrix(mv_tags)\n",
    "frequency.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2. Normal TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>amazing</th>\n",
       "      <th>awesome</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>bit</th>\n",
       "      <th>bye</th>\n",
       "      <th>care</th>\n",
       "      <th>...</th>\n",
       "      <th>type</th>\n",
       "      <th>ve</th>\n",
       "      <th>want</th>\n",
       "      <th>watch</th>\n",
       "      <th>watched</th>\n",
       "      <th>watching</th>\n",
       "      <th>welcome</th>\n",
       "      <th>wow</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84779</td>\n",
       "      <td>0.152357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186844</td>\n",
       "      <td>0.097666</td>\n",
       "      <td>0.190202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191602</td>\n",
       "      <td>0.152357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186844</td>\n",
       "      <td>0.097666</td>\n",
       "      <td>0.190202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122159</td>\n",
       "      <td>0.152357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186844</td>\n",
       "      <td>0.097666</td>\n",
       "      <td>0.190202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165710</td>\n",
       "      <td>0.031588</td>\n",
       "      <td>0.042188</td>\n",
       "      <td>0.026642</td>\n",
       "      <td>0.063162</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.146415</td>\n",
       "      <td>0.027301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03277</td>\n",
       "      <td>0.066668</td>\n",
       "      <td>0.061108</td>\n",
       "      <td>0.156519</td>\n",
       "      <td>0.136781</td>\n",
       "      <td>0.062132</td>\n",
       "      <td>0.054333</td>\n",
       "      <td>0.026951</td>\n",
       "      <td>0.049656</td>\n",
       "      <td>0.191625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151313</td>\n",
       "      <td>0.066975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10044</td>\n",
       "      <td>0.037844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041067</td>\n",
       "      <td>0.085866</td>\n",
       "      <td>0.083611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>166377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>205981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244901</td>\n",
       "      <td>0.333722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>106113</td>\n",
       "      <td>0.183991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>96852</td>\n",
       "      <td>0.146467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>200018</td>\n",
       "      <td>0.370402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089569</td>\n",
       "      <td>0.194508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    action  actually   amazing   awesome      best    better  \\\n",
       "0      84779  0.152357       0.0       0.0       0.0       0.0       0.0   \n",
       "1     191602  0.152357       0.0       0.0       0.0       0.0       0.0   \n",
       "2     122159  0.152357       0.0       0.0       0.0       0.0       0.0   \n",
       "3     165710  0.031588  0.042188  0.026642  0.063162  0.021967  0.011711   \n",
       "4     151313  0.066975       0.0       0.0   0.10044  0.037844       0.0   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "6217  166377       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "6218  205981       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "6219  106113  0.183991       0.0       0.0       0.0       0.0       0.0   \n",
       "6220   96852  0.146467       0.0       0.0       0.0       0.0       0.0   \n",
       "6221  200018  0.370402       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "           bit       bye      care  ...     type        ve      want  \\\n",
       "0     0.186844  0.097666  0.190202  ...      0.0       0.0       0.0   \n",
       "1     0.186844  0.097666  0.190202  ...      0.0       0.0       0.0   \n",
       "2     0.186844  0.097666  0.190202  ...      0.0       0.0       0.0   \n",
       "3     0.014899  0.146415  0.027301  ...  0.03277  0.066668  0.061108   \n",
       "4     0.041067  0.085866  0.083611  ...      0.0       0.0       0.0   \n",
       "...        ...       ...       ...  ...      ...       ...       ...   \n",
       "6217       0.0  0.127951       0.0  ...      0.0       0.0  0.193067   \n",
       "6218       0.0       0.0       0.0  ...      0.0       0.0       0.0   \n",
       "6219       0.0  0.117944       0.0  ...      0.0       0.0  0.355936   \n",
       "6220       0.0   0.09389       0.0  ...      0.0       0.0       0.0   \n",
       "6221       0.0       0.0       0.0  ...      0.0       0.0  0.089569   \n",
       "\n",
       "         watch   watched  watching   welcome       wow      yeah       yes  \n",
       "0          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "1          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "3     0.156519  0.136781  0.062132  0.054333  0.026951  0.049656  0.191625  \n",
       "4     0.093787       0.0  0.214071       0.0  0.123809       0.0  0.135432  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6217       0.0       0.0       0.0       0.0       0.0       0.0   0.13454  \n",
       "6218  0.244901  0.333722       0.0       0.0       0.0       0.0       0.0  \n",
       "6219       0.0       0.0       0.0       0.0   0.22675       0.0       0.0  \n",
       "6220  0.205103       0.0       0.0       0.0       0.0       0.0  0.098725  \n",
       "6221  0.194508       0.0       0.0       0.0   0.11412       0.0  0.124834  \n",
       "\n",
       "[6222 rows x 126 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat, tfidf_columns = parser.get_tfidf_matrix(stop_words='english', min_df=0.2)\n",
    "\n",
    "# Construct dataset with id + word vectors\n",
    "cdata = np.concatenate((parser.dialog_df['movieid'].to_numpy().reshape(len(parser.dialog_df['dialog']), 1), tfidf_mat), axis=1)\n",
    "df_mv_tfidf = pd.DataFrame(cdata, columns=['id'] + tfidf_columns.tolist())\n",
    "df_mv_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Metrics\n",
    "* Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the consine similarity function's denominator has 1e-7 minimum value to avoid the divbyzero.\n",
    "c_sim = lambda X, Y: np.dot(X, Y) / ((norm(X) * norm(Y)) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation function\n",
    "* param:\n",
    "    * data: array, vector space of texts.\n",
    "    * mv: target movie's index\n",
    "    * length: maximum length of recommendation\n",
    "        * default: 5\n",
    "    * simf: Similarity meterices\n",
    "        * default: consine similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(df, index, matrix, length=5, simf=c_sim):\n",
    "    sim = []\n",
    "\n",
    "    if df[df['movieid'] == str(index)].empty:\n",
    "        return sim\n",
    "\n",
    "    target = df[df['movieid'] == str(index)].index[0]\n",
    "\n",
    "    for idx, data in enumerate(matrix):\n",
    "        if idx != target:\n",
    "            sim.append([simf(data, matrix[target]), df.iloc[idx, 0]])\n",
    "    \n",
    "    sim.sort()\n",
    "    sim.reverse()\n",
    "    return sim[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Movie Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981758</td>\n",
       "      <td>140749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981445</td>\n",
       "      <td>159885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979242</td>\n",
       "      <td>81792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.978515</td>\n",
       "      <td>122604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.978132</td>\n",
       "      <td>182731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Similarity Movie Index\n",
       "0    0.981758      140749\n",
       "1    0.981445      159885\n",
       "2    0.979242       81792\n",
       "3    0.978515      122604\n",
       "4    0.978132      182731"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(recommend(parser.dialog_df, 80067, tfidf_mat), columns=['Similarity', 'Movie Index'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirty data test\n",
    "* Since we couldn't find the ditry data, we test it (spam) with hand-written data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>dialog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999995</td>\n",
       "      <td>hi avenger right right hero care care thanks r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999996</td>\n",
       "      <td>comedy scary love animation artistic war sci b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999997</td>\n",
       "      <td>this is a hero movie that kids like to show th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999998</td>\n",
       "      <td>funny funny funny funny funny funny funny funn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>999999</td>\n",
       "      <td>savior hero savior action savior action savior...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movieid                                             dialog\n",
       "0  999995  hi avenger right right hero care care thanks r...\n",
       "1  999996  comedy scary love animation artistic war sci b...\n",
       "2  999997  this is a hero movie that kids like to show th...\n",
       "3  999998  funny funny funny funny funny funny funny funn...\n",
       "4  999999  savior hero savior action savior action savior..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_row = pd.DataFrame({\n",
    "    'movieid': ['999995', '999996', '999997', '999998', '999999'],\n",
    "    'dialog': ['hi avenger right right hero care care thanks right hero hero hero help help pretty planning captain movie recommendations  am fiance super super super of movies hero avenger  hero i captain avenger nigh night and pretty super enjoy hero anything  pretty super might super hero super was a good pretty what s avenger super avenger great super  avenger it avenger about a baby avenger works for a company and gets  adopted it hero avenger funny avenger seems avenger amazing amazing a obsessed hero favorite pretty have hero animated  recommendations amer hero hero action captain avenger captain hero hero america like comedies hero i hero hero avenger a avenger more depth that is a tough one but i will remember  captain captain was hero good one action thanks seems cool thanks for the avenger avenger ready avenger hero if hero are hero end animated great firestick animated animated hero captain action glad  captain captain i could help nice take care hero avenger',\n",
    "    'comedy scary love animation artistic war sci blood hero romantic action recommendation happy fine animation artistic war sci blood hero romantic action comedy scary love comedy scary love war war war hero romantic action comedy hero romantic action comedy',\n",
    "    'this is a hero movie that kids like to show there is many heros with sci fi mechanism and lot of kids likes it much and also parents are liked it too I will gald to introduct that thank you for listening whatsup other recommendation is animation it has robot character that is cute all group of ages liked this movie',\n",
    "    'funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny funny',\n",
    "    'savior hero savior action savior action savior savior savior savior savior action hero savior savior savior action hero savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior savior action savior savior savior savior savior hero savior savior savior savior savior hero savior savior savior savior savior']\n",
    "})\n",
    "dirty_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = parser.dialog_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>amazing</th>\n",
       "      <th>awesome</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>bit</th>\n",
       "      <th>bye</th>\n",
       "      <th>care</th>\n",
       "      <th>...</th>\n",
       "      <th>type</th>\n",
       "      <th>ve</th>\n",
       "      <th>want</th>\n",
       "      <th>watch</th>\n",
       "      <th>watched</th>\n",
       "      <th>watching</th>\n",
       "      <th>welcome</th>\n",
       "      <th>wow</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id action actually amazing awesome best better  bit  bye care  ...  \\\n",
       "6226  999999    1.0      0.0     0.0     0.0  0.0    0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "     type   ve want watch watched watching welcome  wow yeah  yes  \n",
       "6226  0.0  0.0  0.0   0.0     0.0      0.0     0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1 rows x 126 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.dialog_df = pd.concat([original, dirty_row], ignore_index=True)\n",
    "\n",
    "tfidf_mat, tfidf_columns = parser.get_tfidf_matrix(stop_words='english', min_df=0.2)\n",
    "\n",
    "# Construct dataset with id + word vectors\n",
    "cdata = np.concatenate((parser.dialog_df['movieid'].to_numpy().reshape(len(parser.dialog_df['dialog']), 1), tfidf_mat), axis=1)\n",
    "df_mv_tfidf = pd.DataFrame(cdata, columns=['id'] + tfidf_columns.tolist())\n",
    "df_mv_tfidf[df_mv_tfidf['id'] == '999999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Movie Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.688829</td>\n",
       "      <td>195791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.688829</td>\n",
       "      <td>116774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.679817</td>\n",
       "      <td>120270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.647287</td>\n",
       "      <td>79205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.606128</td>\n",
       "      <td>999996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Similarity Movie Index\n",
       "0    0.688829      195791\n",
       "1    0.688829      116774\n",
       "2    0.679817      120270\n",
       "3    0.647287       79205\n",
       "4    0.606128      999996"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(recommend(parser.dialog_df, 999999, tfidf_mat), columns=['Similarity', 'Movie Index'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
