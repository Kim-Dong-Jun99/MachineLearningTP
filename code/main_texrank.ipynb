{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Dataset imports\n",
    "import json\n",
    "\n",
    "# For restoring the dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "# Text manipulations\n",
    "import re\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cosine similarity\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# File download (Golve)\n",
    "import os.path\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download File: GloVe6B.zip - glove100d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../train/glove.6B.100d.txt'\n",
    "\n",
    "if os.path.exists(filepath) is False:\n",
    "    urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"../train/glove.6B.zip\")\n",
    "    zf = zipfile.ZipFile('../train/glove.6B.zip')\n",
    "    zf.extractall() \n",
    "    zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library installation\n",
    "* NLTK - Natural Language toolkit\n",
    "* NetworkX - Structure, Dynamics, and Functions of complex networks Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.8.8)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install nltk\n",
    "!python -m pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK: Library for NLP Process\n",
    "* Usage:\n",
    "    * nltk.corpus.**stopwords**: stopwords of specific language\n",
    "    * nltk.tokenize.**RegexpTokenizer, sent_tokenize, word_tokenize**: Tokenize the input sentences\n",
    "    * nltk.stem.**WordNetLemmatizer**: Lemmatize the word net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetworkX: Library for PageRank(TextRank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redial Parser\n",
    "A separated library for parsing the redial dataset\n",
    "\n",
    "class **RedialParser**\n",
    "- Restore(): Restore train, test, and movie dataset to initial state\n",
    "   * return:\n",
    "        * None\n",
    "- Movies(train): Get movie list in dataset\n",
    "   * param:\n",
    "        * train (bool): Target dataset, (train=True, test=False, all=None)\n",
    "   * return:\n",
    "        * dict: {index, MovieName}\n",
    "- describe(): Describe its datasets\n",
    "   * return:\n",
    "        * None\n",
    "- train: Train data of ReDial.\n",
    "- test: Test data of ReDial.\n",
    "- movie: Movie mention counts for ReDial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    TODO: initialization function for dataset reads\n",
    "\n",
    "        :arg\n",
    "            path (str): Dataset path.\n",
    "        :return\n",
    "            tuple: (train, test, df_mention)\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    for line in open(f\"{path}/train_data.jsonl\", \"r\"):\n",
    "        train_data.append(json.loads(line))\n",
    "\n",
    "    test_data = []\n",
    "    for line in open(f\"{path}/test_data.jsonl\", \"r\"):\n",
    "        test_data.append(json.loads(line))\n",
    "\n",
    "    mention_dataframe = pd.read_csv(f\"{path}/movies_with_mentions.csv\")\n",
    "\n",
    "    return train_data, test_data, mention_dataframe\n",
    "\n",
    "\n",
    "class RedialParser:\n",
    "    def __init__(self, path):\n",
    "        self.train, self.test, self.movie = load_data(path)\n",
    "\n",
    "        self._global_movie_list = None  # list of all movie names (global movie name data)\n",
    "        self._global_msg_list = None  # list of whole lines (global line data)\n",
    "        self._local_movie_list = None  # list of movie names (local movie name data)\n",
    "        self._local_msg_list = None  # list of lines (local line data)\n",
    "\n",
    "        self.dialog_df = None  # Sum of dialogs for each movie indices\n",
    "\n",
    "        self.__train = deepcopy(self.train)\n",
    "        self.__test = deepcopy(self.test)\n",
    "        self.__movie = deepcopy(self.movie)\n",
    "\n",
    "        # Import 100-D GloVe Embedding Vector\n",
    "        self.__glove_dict = dict()\n",
    "        f = open('../train/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "        for line in f:\n",
    "            word_vector = line.split()\n",
    "            word = word_vector[0]\n",
    "            word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
    "            self.__glove_dict[word] = word_vector_arr\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    def Restore(self):\n",
    "        \"\"\"\n",
    "        TODO: Restore train, test, and movie dataset to initial state\n",
    "        \"\"\"\n",
    "        self.train = deepcopy(self.__train)\n",
    "        self.test = deepcopy(self.__test)\n",
    "        self.movie = deepcopy(self.__movie)\n",
    "\n",
    "\n",
    "    def Movies(self, train=True) -> dict:\n",
    "        \"\"\"\n",
    "        TODO: Get movie list in dataset\n",
    "\n",
    "            :arg\n",
    "                train (bool): Target dataset, (train=True, test=False, all=None)\n",
    "            :return\n",
    "                dict: {index, MovieName}\n",
    "        \"\"\"\n",
    "        if train is None:\n",
    "            result = self.Movies()\n",
    "            result.update(self.Movies(False))\n",
    "            return result\n",
    "\n",
    "        target = None\n",
    "        if train is True:\n",
    "            target = self.train\n",
    "        elif train is False:\n",
    "            target = self.test\n",
    "\n",
    "        result = {}\n",
    "\n",
    "        if target is not None:\n",
    "            for elem in target:\n",
    "                result.update(elem['movieMentions'])\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        TODO: Describe its datasets\n",
    "        \"\"\"\n",
    "        len1, len2 = len(self.train), len(self.test)\n",
    "        n1, n2 = 0, 0\n",
    "        m1, m2 = 0, 0\n",
    "\n",
    "        for e in self.train:\n",
    "            n1 += len(e['movieMentions'])\n",
    "            m1 += len(e['messages'])\n",
    "        for e in self.test:\n",
    "            n2 += len(e['movieMentions'])\n",
    "            m2 += len(e['messages'])\n",
    "\n",
    "        print('Brief information:\\n'\n",
    "              f'Length of train data: {len1}\\n'\n",
    "              f'Length of test data: {len2}\\n\\n'\n",
    "              'Data information:\\n'\n",
    "              f'Key parameters: {list(self.train[0].keys())}\\n'\n",
    "              f'Key parameters in Questions: {list(list(self.train[0][\"respondentQuestions\"].values())[0].keys())}\\n'\n",
    "              f'Key parameters in messages: {list(self.train[0][\"messages\"][0].keys())}\\n\\n'\n",
    "              'Context information:\\n'\n",
    "              f'Total mentioned movie number (train): {n1}\\n'\n",
    "              f'Total mentioned movie number in unique (train): {len(self.Movies())}\\n'\n",
    "              f'Total message number (train): {m1}\\n'\n",
    "              f'Total mentioned movie number (test): {n2}\\n'\n",
    "              f'Total mentioned movie number in unique (test): {len(self.Movies(False))}\\n'\n",
    "              f'Total message number (test): {m2}\\n'\n",
    "              f'Average mentioned movie numbers per conversation (train): {n1 / len1}\\n'\n",
    "              f'Average message numbers per conversation (train): {m1 / len1}\\n'\n",
    "              f'Average mentioned movie numbers per conversation (test): {n2 / len2}\\n'\n",
    "              f'Average message numbers per conversation (test): {m2 / len2}\\n\\n'\n",
    "              , end='')\n",
    "    \n",
    "\n",
    "    def preprocessing(self):\n",
    "        \"\"\"\n",
    "        TODO: Regroup train dataset into purposed structure and clean up data\n",
    "        \"\"\"\n",
    "        \n",
    "        ran = range(len(self.train))\n",
    "\n",
    "        # initialize list\n",
    "        self._global_movie_list = []\n",
    "        self._global_msg_list = []\n",
    "        self._local_movie_list = [[] for _ in ran]\n",
    "        self._local_msg_list = [[] for _ in ran]\n",
    "\n",
    "        for i, data in enumerate(self.train):\n",
    "            for msg in data['messages']:  # append line to the lists\n",
    "                self._local_msg_list[i].append(msg['text'])\n",
    "                self._global_msg_list.append(msg['text'])\n",
    "\n",
    "            # Extract movie indices\n",
    "            for idx, line in enumerate(self._local_msg_list[i]):\n",
    "                numbers = re.findall(r'@\\d+', line)  # find number keywords (ex: @12345)\n",
    "                for number in numbers:\n",
    "                    self._local_movie_list[i].append(number[1:])\n",
    "                    self._global_movie_list.append(number[1:])\n",
    "\n",
    "                    # Remove index string\n",
    "                    pos = line.index(number)\n",
    "                    line = self._local_msg_list[i][idx] = line[0: pos] + line[pos + len(number): len(line)]\n",
    "\n",
    "        # Construct dialog dataframe\n",
    "        self.dialog_df = pd.DataFrame(columns=[\"movieid\", \"dialog\"])\n",
    "\n",
    "        for lines, movies in zip(self._local_msg_list, self._local_movie_list):\n",
    "            dig = ''\n",
    "            for line in lines:  # concatenate all sentences in related message dialog\n",
    "                dig += ' ' + str(line)\n",
    "            \n",
    "            for mv in movies:\n",
    "                if self.dialog_df[self.dialog_df['movieid'] == mv].empty:\n",
    "                    newrow = pd.DataFrame({'movieid': [mv], 'dialog': [dig]}, columns=self.dialog_df.columns)\n",
    "                    self.dialog_df = pd.concat([self.dialog_df, newrow], ignore_index=True)\n",
    "                else:\n",
    "                    target = self.dialog_df[self.dialog_df['movieid'] == mv].index[0]\n",
    "                    self.dialog_df.iloc[target, 1] = self.dialog_df.iloc[target, 1] + ' ' + dig\n",
    "        \n",
    "        # Drop NaN with empty sentence\n",
    "        self.dialog_df['dialog'].dropna(how='any', inplace=True)\n",
    "\n",
    "    \n",
    "    def make_summary(self):\n",
    "        \"\"\"\n",
    "        TODO: make summary of dialog using GloVe + TextRank\n",
    "        \"\"\"\n",
    "        self.dialog_df['sentences'] = self.dialog_df['dialog'].apply(sent_tokenize)\n",
    "\n",
    "        stop_words = stopwords.words('english')\n",
    "\n",
    "        # tokenization\n",
    "        def tokenization(sentences):\n",
    "            return [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "        # Preprocessing\n",
    "        def preprocess_sentence(sentence):\n",
    "            # lower case\n",
    "            sentence = [re.sub(r'[^a-zA-z\\s]', '', word).lower() for word in sentence]\n",
    "            # remove stopwords\n",
    "            return [word for word in sentence if word not in stop_words and word]\n",
    "\n",
    "        # Do preproessing for all sentences\n",
    "        def preprocess_sentences(sentences):\n",
    "            return [preprocess_sentence(sentence) for sentence in sentences]\n",
    "\n",
    "        self.dialog_df['tokenized_sentences'] = self.dialog_df['sentences'].apply(tokenization)\n",
    "        self.dialog_df['tokenized_sentences'] = self.dialog_df['tokenized_sentences'].apply(preprocess_sentences)\n",
    "\n",
    "        # Embedding Dimension = 100 = GloVe dimension\n",
    "        embedding_dim = 100\n",
    "        zero_vector = np.zeros(embedding_dim)\n",
    "\n",
    "        # Obtain the sentence vector from the mean of words\n",
    "        def calculate_sentence_vector(sentence):\n",
    "            if len(sentence) != 0:\n",
    "                return sum([self.__glove_dict.get(word, zero_vector) for word in sentence]) / len(sentence)\n",
    "            else:\n",
    "                return zero_vector\n",
    "        \n",
    "        def sentences_to_vectors(sentences):\n",
    "            return [calculate_sentence_vector(sentence) for sentence in sentences]\n",
    "        \n",
    "        sentence_range = range(101)\n",
    "        drop_list = []\n",
    "\n",
    "        for idx, val in enumerate(self.dialog_df['tokenized_sentences'].values.tolist()):\n",
    "            if len(val) not in sentence_range:\n",
    "                drop_list.append(self.dialog_df.iloc[idx, 0])\n",
    "        \n",
    "        for id in drop_list:\n",
    "            drop_id = self.dialog_df[self.dialog_df['movieid'] == id].index\n",
    "            self.dialog_df.drop(drop_id, inplace=True)\n",
    "\n",
    "        # Do sentence embedding\n",
    "        self.dialog_df['SentenceEmbedding'] = self.dialog_df['tokenized_sentences'].apply(sentences_to_vectors)\n",
    "        self.dialog_df[['SentenceEmbedding']]\n",
    "\n",
    "        def similarity_matrix(sentence_embedding):\n",
    "            length = len(sentence_embedding)\n",
    "            sim_mat = np.zeros([length, length])\n",
    "\n",
    "            for i in range(length):\n",
    "                for j in range(length):\n",
    "                    sim_mat[i][j] = cosine_similarity(sentence_embedding[i].reshape(1, embedding_dim), sentence_embedding[j].reshape(1, embedding_dim))[0, 0]\n",
    "            return sim_mat\n",
    "        \n",
    "        # Get similarity matrix\n",
    "        self.dialog_df['SimMatrix'] = self.dialog_df['SentenceEmbedding'].apply(similarity_matrix)\n",
    "\n",
    "        # TextRank\n",
    "        def calculate_score(sim_matrix):\n",
    "            nx_graph = nx.from_numpy_array(sim_matrix)\n",
    "            scores = nx.pagerank_numpy(nx_graph)\n",
    "            return scores\n",
    "        \n",
    "        self.dialog_df['score'] = self.dialog_df['SimMatrix'].apply(calculate_score)\n",
    "        \n",
    "        # Write summary using TextRank score\n",
    "        def ranked_sentences(sentences, scores, n=3):\n",
    "            top_scores = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "            top_n_sentences = [sentence for score, sentence in top_scores[:n]]\n",
    "            return \" \".join(top_n_sentences)\n",
    "\n",
    "        self.dialog_df['summary'] = self.dialog_df.apply(lambda x: ranked_sentences(x.sentences, x.score), axis=1)\n",
    "    \n",
    "\n",
    "    def get_frequency_matrix(self, tags):\n",
    "        \"\"\"\n",
    "        TODO: compute the frequency of tag words to obtain the TF-IDFs matrix\n",
    "\n",
    "            :arg\n",
    "                tags (list): list of key words.\n",
    "            :return\n",
    "                pandas.DataFrame: frequency matrix of tag words.\n",
    "        \"\"\"\n",
    "        stop_word_eng = set(stopwords.words('english'))\n",
    "        ran = range(len(self.train))\n",
    "\n",
    "        msg_list = deepcopy(self._local_msg_list)\n",
    "\n",
    "        for i in ran:\n",
    "            msg_list[i] = [j for j in msg_list[i] if j not in stop_word_eng]  # Clear stopwords\n",
    "\n",
    "        # Lemmatizer class\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = RegexpTokenizer('[\\w]+')\n",
    "\n",
    "        x = pd.DataFrame(columns=['id'] + tags)\n",
    "\n",
    "        for idx, msg in enumerate(msg_list):\n",
    "            result_pre_lem = [token.tokenize(j) for j in msg]\n",
    "            middle_pre_lem = [r for j in result_pre_lem for r in j]\n",
    "            final_lem = [lemmatizer.lemmatize(j) for j in middle_pre_lem if not j in stop_word_eng]  # Remove stopword\n",
    "\n",
    "            # Lemmatization\n",
    "            english = pd.Series(final_lem)\n",
    "            for word in english:\n",
    "                if word in tags:\n",
    "                    for movie in self._local_movie_list[idx]:\n",
    "                        if x[x['id'] == movie].empty:\n",
    "                            new_row = pd.DataFrame({'id': [movie]}, columns=x.columns)\n",
    "                            x = pd.concat([x, new_row], ignore_index=True)\n",
    "                            x.fillna(0, inplace=True)\n",
    "                        x.loc[x['id'] == movie, word] += 1\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def get_tfidf_matrix(self, **tfidf_keys):\n",
    "        \"\"\"\n",
    "        TODO: Compute TF-IDFs matrix\n",
    "\n",
    "            :arg\n",
    "                tfidf_keys(keyword dict): TfidfVectorizer parameters\n",
    "            :return\n",
    "                numpy.ndrarry: TF-IDFs matrix\n",
    "                numpy.ndarray: feature name of TF-IDFs (word)\n",
    "        \"\"\"\n",
    "        # Vectorizer class\n",
    "        tfidf = TfidfVectorizer(**tfidf_keys)  # Ignore English Stopwords\n",
    "\n",
    "        # Obtain matrix\n",
    "        tfidf_df = tfidf.fit_transform(self.dialog_df['dialog'])\n",
    "\n",
    "        return tfidf_df.toarray(), tfidf.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n",
    "Import dataset, describe it briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brief information:\n",
      "Length of train data: 10006\n",
      "Length of test data: 1342\n",
      "\n",
      "Data information:\n",
      "Key parameters: ['movieMentions', 'respondentQuestions', 'messages', 'conversationId', 'respondentWorkerId', 'initiatorWorkerId', 'initiatorQuestions']\n",
      "Key parameters in Questions: ['suggested', 'seen', 'liked']\n",
      "Key parameters in messages: ['timeOffset', 'text', 'senderWorkerId', 'messageId']\n",
      "\n",
      "Context information:\n",
      "Total mentioned movie number (train): 52918\n",
      "Total mentioned movie number in unique (train): 6223\n",
      "Total message number (train): 182150\n",
      "Total mentioned movie number (test): 7154\n",
      "Total mentioned movie number in unique (test): 2007\n",
      "Total message number (test): 23952\n",
      "Average mentioned movie numbers per conversation (train): 5.288626823905656\n",
      "Average message numbers per conversation (train): 18.20407755346792\n",
      "Average mentioned movie numbers per conversation (test): 5.330849478390462\n",
      "Average message numbers per conversation (test): 17.847988077496275\n",
      "\n",
      "length of train dataset: 10006\n"
     ]
    }
   ],
   "source": [
    "parser = RedialParser('../dataset')\n",
    "parser.describe()  # Describe read dataset\n",
    "\n",
    "# Size of train data\n",
    "num = len(parser.train)\n",
    "print(f'length of train dataset: {num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Clear the special character and extract the text and movie indices\n",
    "- example: \"I like animations like @84779 and @191602\" → [i like animations like  and ], [84779, 191602]\n",
    "\n",
    "\n",
    "Specific:\n",
    "* Transform dataset structure.\n",
    "    * Original: [movieMentions, {messages}, conversationId, ...]\n",
    "    * Transformed: [movie_indices], [message_contexts], [[1st_movie_index], [2nd_...], ...], [[1st_message_context], [2nd_...], ...]\n",
    "    * Dialog Dataframe (*self.dialog_df*): {'movie_id': '1st message' + '2nd message' + ...} - Used in generation of **TF-IDF** matrix\n",
    "* Recognize movie indices\n",
    "    * **@** recognition: use re library's *findall(@\\d+)* function, it only detects '@' + index strings.\n",
    "* Clean up meaningless values\n",
    "    * Special characters: use re library's format *\\w+*, it only receives widechar characters.\n",
    "    * Movie index: remove context of them by using text slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>dialog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84779</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191602</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122159</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165710</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151313</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>166377</td>\n",
       "      <td>Hi Hello there I LIKE SCI-FI genetic modifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>205981</td>\n",
       "      <td>What kind of movies do you like ? hello! I am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>106113</td>\n",
       "      <td>hi HI, I like Sci-fi movies Genetic modificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>96852</td>\n",
       "      <td>hi Hi !! have a good day which kind of movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>200018</td>\n",
       "      <td>Hello! hi how can i help you So some of the m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieid                                             dialog\n",
       "0      84779   Hi there, how are you? I'm looking for movie ...\n",
       "1     191602   Hi there, how are you? I'm looking for movie ...\n",
       "2     122159   Hi there, how are you? I'm looking for movie ...\n",
       "3     165710   Hi there, how are you? I'm looking for movie ...\n",
       "4     151313   Hi there, how are you? I'm looking for movie ...\n",
       "...      ...                                                ...\n",
       "6217  166377   Hi Hello there I LIKE SCI-FI genetic modifica...\n",
       "6218  205981   What kind of movies do you like ? hello! I am...\n",
       "6219  106113   hi HI, I like Sci-fi movies Genetic modificat...\n",
       "6220   96852   hi Hi !! have a good day which kind of movie ...\n",
       "6221  200018   Hello! hi how can i help you So some of the m...\n",
       "\n",
       "[6222 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.preprocessing()\n",
    "parser.dialog_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "* 1. Obtain keywords (summary) using **TextRank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15640\\205118989.py:243: DeprecationWarning: networkx.pagerank_numpy is deprecated and will be removed in NetworkX 3.0, use networkx.pagerank instead.\n",
      "  scores = nx.pagerank_numpy(nx_graph)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:354: FutureWarning: google_matrix will return an np.ndarray instead of a np.matrix in\n",
      "NetworkX version 3.0.\n",
      "  M = google_matrix(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>dialog</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>SentenceEmbedding</th>\n",
       "      <th>SimMatrix</th>\n",
       "      <th>score</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84779</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "      <td>[ Hi there, how are you?, I'm looking for movi...</td>\n",
       "      <td>[[hi], [looking, movie, recommendations, okay]...</td>\n",
       "      <td>[[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...</td>\n",
       "      <td>[[0.9999999403953552, 0.24245616793632507, 0.2...</td>\n",
       "      <td>{0: 0.06536974281629612, 1: 0.1115491066609117...</td>\n",
       "      <td>It is animated, sci fi, and has action Glad I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191602</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "      <td>[ Hi there, how are you?, I'm looking for movi...</td>\n",
       "      <td>[[hi], [looking, movie, recommendations, okay]...</td>\n",
       "      <td>[[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...</td>\n",
       "      <td>[[0.9999999403953552, 0.24245616793632507, 0.2...</td>\n",
       "      <td>{0: 0.06536974281629612, 1: 0.1115491066609117...</td>\n",
       "      <td>It is animated, sci fi, and has action Glad I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122159</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "      <td>[ Hi there, how are you?, I'm looking for movi...</td>\n",
       "      <td>[[hi], [looking, movie, recommendations, okay]...</td>\n",
       "      <td>[[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...</td>\n",
       "      <td>[[0.9999999403953552, 0.24245616793632507, 0.2...</td>\n",
       "      <td>{0: 0.06536974281629612, 1: 0.1115491066609117...</td>\n",
       "      <td>It is animated, sci fi, and has action Glad I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151313</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "      <td>[ Hi there, how are you?, I'm looking for movi...</td>\n",
       "      <td>[[hi], [looking, movie, recommendations, okay]...</td>\n",
       "      <td>[[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...</td>\n",
       "      <td>[[0.9999999403953552, 0.24245616793632507, 0.2...</td>\n",
       "      <td>{0: 0.005749033404559646, 1: 0.012240076161428...</td>\n",
       "      <td>Like  for example I like comedies but I prefer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>204322</td>\n",
       "      <td>Hi, did you see  ? Yes it was a pretty good m...</td>\n",
       "      <td>[ Hi, did you see  ?, Yes it was a pretty good...</td>\n",
       "      <td>[[hi, see], [yes, pretty, good, movie], [would...</td>\n",
       "      <td>[[-0.197045, 0.39572, 0.75997496, 0.09388, -0....</td>\n",
       "      <td>[[0.9999998807907104, 0.6657719016075134, 0.59...</td>\n",
       "      <td>{0: 0.032654807746370675, 1: 0.040617095075637...</td>\n",
       "      <td>Hello how are you, what are your favorite kind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>166377</td>\n",
       "      <td>Hi Hello there I LIKE SCI-FI genetic modifica...</td>\n",
       "      <td>[ Hi Hello there I LIKE SCI-FI genetic modific...</td>\n",
       "      <td>[[hi, hello, like, scifi, genetic, modificatio...</td>\n",
       "      <td>[[0.011004001, 0.2420111, 0.39807892, -0.12358...</td>\n",
       "      <td>[[1.0000001192092896, 0.6454883217811584, 0.66...</td>\n",
       "      <td>{0: 0.0692688154877309, 1: 0.06378854397892308...</td>\n",
       "      <td>You might would like  , which is a genetic mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>205981</td>\n",
       "      <td>What kind of movies do you like ? hello! I am...</td>\n",
       "      <td>[ What kind of movies do you like ?, hello!, I...</td>\n",
       "      <td>[[kind, movies, like], [hello], [looking, movi...</td>\n",
       "      <td>[[-0.030508334, 0.43740702, 0.4855567, -0.4959...</td>\n",
       "      <td>[[1.0, 0.3861870765686035, 0.8655173182487488,...</td>\n",
       "      <td>{0: 0.08503767938796901, 1: 0.0571018466271147...</td>\n",
       "      <td>It was a remake, or I guess a updated version ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>106113</td>\n",
       "      <td>hi HI, I like Sci-fi movies Genetic modificat...</td>\n",
       "      <td>[ hi HI, I like Sci-fi movies Genetic modifica...</td>\n",
       "      <td>[[hi, hi, like, scifi, movies, genetic, modifi...</td>\n",
       "      <td>[[0.06543327, 0.23472007, 0.48408842, 0.000198...</td>\n",
       "      <td>[[1.0, 0.7383857369422913, 0.8496346473693848,...</td>\n",
       "      <td>{0: 0.15428587521971038, 1: 0.1521021893291355...</td>\n",
       "      <td>Wow sounds good, haven't seen it guess i'll ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>96852</td>\n",
       "      <td>hi Hi !! have a good day which kind of movie ...</td>\n",
       "      <td>[ hi Hi !!, have a good day which kind of movi...</td>\n",
       "      <td>[[hi, hi], [good, day, kind, movie, like], [li...</td>\n",
       "      <td>[[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...</td>\n",
       "      <td>[[0.9999999403953552, 0.28580141067504883, 0.2...</td>\n",
       "      <td>{0: 0.07542525902780071, 1: 0.1299216272022606...</td>\n",
       "      <td>have a good day which kind of movie do you lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>200018</td>\n",
       "      <td>Hello! hi how can i help you So some of the m...</td>\n",
       "      <td>[ Hello!, hi how can i help you So some of the...</td>\n",
       "      <td>[[hello], [hi, help, movies, really, enjoy, th...</td>\n",
       "      <td>[[0.26688, 0.39632, 0.6169, -0.77451, -0.1039,...</td>\n",
       "      <td>[[0.9999999403953552, 0.37012484669685364, 0.3...</td>\n",
       "      <td>{0: 0.034745318070020716, 1: 0.060032179373261...</td>\n",
       "      <td>is one great example action packed movies wow!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4691 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieid                                             dialog  \\\n",
       "0      84779   Hi there, how are you? I'm looking for movie ...   \n",
       "1     191602   Hi there, how are you? I'm looking for movie ...   \n",
       "2     122159   Hi there, how are you? I'm looking for movie ...   \n",
       "4     151313   Hi there, how are you? I'm looking for movie ...   \n",
       "10    204322   Hi, did you see  ? Yes it was a pretty good m...   \n",
       "...      ...                                                ...   \n",
       "6217  166377   Hi Hello there I LIKE SCI-FI genetic modifica...   \n",
       "6218  205981   What kind of movies do you like ? hello! I am...   \n",
       "6219  106113   hi HI, I like Sci-fi movies Genetic modificat...   \n",
       "6220   96852   hi Hi !! have a good day which kind of movie ...   \n",
       "6221  200018   Hello! hi how can i help you So some of the m...   \n",
       "\n",
       "                                              sentences  \\\n",
       "0     [ Hi there, how are you?, I'm looking for movi...   \n",
       "1     [ Hi there, how are you?, I'm looking for movi...   \n",
       "2     [ Hi there, how are you?, I'm looking for movi...   \n",
       "4     [ Hi there, how are you?, I'm looking for movi...   \n",
       "10    [ Hi, did you see  ?, Yes it was a pretty good...   \n",
       "...                                                 ...   \n",
       "6217  [ Hi Hello there I LIKE SCI-FI genetic modific...   \n",
       "6218  [ What kind of movies do you like ?, hello!, I...   \n",
       "6219  [ hi HI, I like Sci-fi movies Genetic modifica...   \n",
       "6220  [ hi Hi !!, have a good day which kind of movi...   \n",
       "6221  [ Hello!, hi how can i help you So some of the...   \n",
       "\n",
       "                                    tokenized_sentences  \\\n",
       "0     [[hi], [looking, movie, recommendations, okay]...   \n",
       "1     [[hi], [looking, movie, recommendations, okay]...   \n",
       "2     [[hi], [looking, movie, recommendations, okay]...   \n",
       "4     [[hi], [looking, movie, recommendations, okay]...   \n",
       "10    [[hi, see], [yes, pretty, good, movie], [would...   \n",
       "...                                                 ...   \n",
       "6217  [[hi, hello, like, scifi, genetic, modificatio...   \n",
       "6218  [[kind, movies, like], [hello], [looking, movi...   \n",
       "6219  [[hi, hi, like, scifi, movies, genetic, modifi...   \n",
       "6220  [[hi, hi], [good, day, kind, movie, like], [li...   \n",
       "6221  [[hello], [hi, help, movies, really, enjoy, th...   \n",
       "\n",
       "                                      SentenceEmbedding  \\\n",
       "0     [[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...   \n",
       "1     [[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...   \n",
       "2     [[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...   \n",
       "4     [[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...   \n",
       "10    [[-0.197045, 0.39572, 0.75997496, 0.09388, -0....   \n",
       "...                                                 ...   \n",
       "6217  [[0.011004001, 0.2420111, 0.39807892, -0.12358...   \n",
       "6218  [[-0.030508334, 0.43740702, 0.4855567, -0.4959...   \n",
       "6219  [[0.06543327, 0.23472007, 0.48408842, 0.000198...   \n",
       "6220  [[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...   \n",
       "6221  [[0.26688, 0.39632, 0.6169, -0.77451, -0.1039,...   \n",
       "\n",
       "                                              SimMatrix  \\\n",
       "0     [[0.9999999403953552, 0.24245616793632507, 0.2...   \n",
       "1     [[0.9999999403953552, 0.24245616793632507, 0.2...   \n",
       "2     [[0.9999999403953552, 0.24245616793632507, 0.2...   \n",
       "4     [[0.9999999403953552, 0.24245616793632507, 0.2...   \n",
       "10    [[0.9999998807907104, 0.6657719016075134, 0.59...   \n",
       "...                                                 ...   \n",
       "6217  [[1.0000001192092896, 0.6454883217811584, 0.66...   \n",
       "6218  [[1.0, 0.3861870765686035, 0.8655173182487488,...   \n",
       "6219  [[1.0, 0.7383857369422913, 0.8496346473693848,...   \n",
       "6220  [[0.9999999403953552, 0.28580141067504883, 0.2...   \n",
       "6221  [[0.9999999403953552, 0.37012484669685364, 0.3...   \n",
       "\n",
       "                                                  score  \\\n",
       "0     {0: 0.06536974281629612, 1: 0.1115491066609117...   \n",
       "1     {0: 0.06536974281629612, 1: 0.1115491066609117...   \n",
       "2     {0: 0.06536974281629612, 1: 0.1115491066609117...   \n",
       "4     {0: 0.005749033404559646, 1: 0.012240076161428...   \n",
       "10    {0: 0.032654807746370675, 1: 0.040617095075637...   \n",
       "...                                                 ...   \n",
       "6217  {0: 0.0692688154877309, 1: 0.06378854397892308...   \n",
       "6218  {0: 0.08503767938796901, 1: 0.0571018466271147...   \n",
       "6219  {0: 0.15428587521971038, 1: 0.1521021893291355...   \n",
       "6220  {0: 0.07542525902780071, 1: 0.1299216272022606...   \n",
       "6221  {0: 0.034745318070020716, 1: 0.060032179373261...   \n",
       "\n",
       "                                                summary  \n",
       "0     It is animated, sci fi, and has action Glad I ...  \n",
       "1     It is animated, sci fi, and has action Glad I ...  \n",
       "2     It is animated, sci fi, and has action Glad I ...  \n",
       "4     Like  for example I like comedies but I prefer...  \n",
       "10    Hello how are you, what are your favorite kind...  \n",
       "...                                                 ...  \n",
       "6217  You might would like  , which is a genetic mod...  \n",
       "6218  It was a remake, or I guess a updated version ...  \n",
       "6219  Wow sounds good, haven't seen it guess i'll ha...  \n",
       "6220  have a good day which kind of movie do you lik...  \n",
       "6221  is one great example action packed movies wow!...  \n",
       "\n",
       "[4691 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.make_summary()\n",
    "parser.dialog_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2. Extract words and their counts related to the movies. (Did not used, only for eye inspection.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedy</th>\n",
       "      <th>scary</th>\n",
       "      <th>love</th>\n",
       "      <th>animation</th>\n",
       "      <th>artistic</th>\n",
       "      <th>war</th>\n",
       "      <th>sci</th>\n",
       "      <th>blood</th>\n",
       "      <th>hero</th>\n",
       "      <th>romantic</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5036.000000</td>\n",
       "      <td>5036.000000</td>\n",
       "      <td>5036.000000</td>\n",
       "      <td>5036.000000</td>\n",
       "      <td>5036.000000</td>\n",
       "      <td>5036.000000</td>\n",
       "      <td>5036.000000</td>\n",
       "      <td>5036.000000</td>\n",
       "      <td>5036.000000</td>\n",
       "      <td>5036.000000</td>\n",
       "      <td>5036.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.681890</td>\n",
       "      <td>1.295075</td>\n",
       "      <td>7.517871</td>\n",
       "      <td>0.195790</td>\n",
       "      <td>0.006553</td>\n",
       "      <td>0.447975</td>\n",
       "      <td>0.828634</td>\n",
       "      <td>0.056394</td>\n",
       "      <td>0.294281</td>\n",
       "      <td>1.016878</td>\n",
       "      <td>3.796267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.056695</td>\n",
       "      <td>9.917951</td>\n",
       "      <td>19.831492</td>\n",
       "      <td>1.552968</td>\n",
       "      <td>0.092181</td>\n",
       "      <td>3.744135</td>\n",
       "      <td>5.195543</td>\n",
       "      <td>0.439369</td>\n",
       "      <td>2.343911</td>\n",
       "      <td>5.782513</td>\n",
       "      <td>18.478270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>437.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>648.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            comedy        scary         love    animation     artistic  \\\n",
       "count  5036.000000  5036.000000  5036.000000  5036.000000  5036.000000   \n",
       "mean      5.681890     1.295075     7.517871     0.195790     0.006553   \n",
       "std      21.056695     9.917951    19.831492     1.552968     0.092181   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     2.000000     0.000000     0.000000   \n",
       "75%       3.000000     0.000000     6.000000     0.000000     0.000000   \n",
       "max     437.000000   482.000000   355.000000    64.000000     2.000000   \n",
       "\n",
       "               war          sci        blood         hero     romantic  \\\n",
       "count  5036.000000  5036.000000  5036.000000  5036.000000  5036.000000   \n",
       "mean      0.447975     0.828634     0.056394     0.294281     1.016878   \n",
       "std       3.744135     5.195543     0.439369     2.343911     5.782513   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max     159.000000   143.000000    15.000000    78.000000   139.000000   \n",
       "\n",
       "            action  \n",
       "count  5036.000000  \n",
       "mean      3.796267  \n",
       "std      18.478270  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       2.000000  \n",
       "max     648.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tag words words related with movie genres\n",
    "mv_tags = ['comedy','scary','love','animation','artistic','war','sci','blood','hero','romantic','action']\n",
    "frequency = parser.get_frequency_matrix(mv_tags)\n",
    "frequency.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3. TextRank used TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>action</th>\n",
       "      <th>awesome</th>\n",
       "      <th>bye</th>\n",
       "      <th>check</th>\n",
       "      <th>classic</th>\n",
       "      <th>comedy</th>\n",
       "      <th>cool</th>\n",
       "      <th>day</th>\n",
       "      <th>did</th>\n",
       "      <th>...</th>\n",
       "      <th>today</th>\n",
       "      <th>try</th>\n",
       "      <th>type</th>\n",
       "      <th>ve</th>\n",
       "      <th>want</th>\n",
       "      <th>watch</th>\n",
       "      <th>watched</th>\n",
       "      <th>welcome</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84779</td>\n",
       "      <td>0.210353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196607</td>\n",
       "      <td>0.21432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191602</td>\n",
       "      <td>0.210353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196607</td>\n",
       "      <td>0.21432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122159</td>\n",
       "      <td>0.210353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196607</td>\n",
       "      <td>0.21432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151313</td>\n",
       "      <td>0.082024</td>\n",
       "      <td>0.126055</td>\n",
       "      <td>0.093213</td>\n",
       "      <td>0.080787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>0.19893</td>\n",
       "      <td>0.098133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>166377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>205981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255874</td>\n",
       "      <td>0.383466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4688</th>\n",
       "      <td>106113</td>\n",
       "      <td>0.206346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4689</th>\n",
       "      <td>96852</td>\n",
       "      <td>0.17456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099186</td>\n",
       "      <td>0.114617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4690</th>\n",
       "      <td>200018</td>\n",
       "      <td>0.430278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104734</td>\n",
       "      <td>0.207366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4691 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    action   awesome       bye     check   classic    comedy  \\\n",
       "0      84779  0.210353       0.0  0.119524       0.0       0.0  0.196607   \n",
       "1     191602  0.210353       0.0  0.119524       0.0       0.0  0.196607   \n",
       "2     122159  0.210353       0.0  0.119524       0.0       0.0  0.196607   \n",
       "3     151313  0.082024  0.126055  0.093213  0.080787       0.0  0.076664   \n",
       "4     204322       0.0       0.0  0.122967       0.0       0.0  0.101136   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "4686  166377       0.0       0.0  0.146876       0.0       0.0       0.0   \n",
       "4687  205981       0.0       0.0       0.0   0.26146       0.0       0.0   \n",
       "4688  106113  0.206346       0.0  0.117247       0.0  0.191926       0.0   \n",
       "4689   96852   0.17456       0.0  0.099186  0.114617       0.0       0.0   \n",
       "4690  200018  0.430278       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "         cool       day       did  ... today       try type   ve      want  \\\n",
       "0     0.21432       0.0       0.0  ...   0.0       0.0  0.0  0.0       0.0   \n",
       "1     0.21432       0.0       0.0  ...   0.0       0.0  0.0  0.0       0.0   \n",
       "2     0.21432       0.0       0.0  ...   0.0       0.0  0.0  0.0       0.0   \n",
       "3      0.2925   0.19893  0.098133  ...   0.0  0.040855  0.0  0.0       0.0   \n",
       "4         0.0       0.0   0.17261  ...   0.0       0.0  0.0  0.0       0.0   \n",
       "...       ...       ...       ...  ...   ...       ...  ...  ...       ...   \n",
       "4686      0.0       0.0       0.0  ...   0.0       0.0  0.0  0.0  0.251678   \n",
       "4687      0.0       0.0       0.0  ...   0.0       0.0  0.0  0.0       0.0   \n",
       "4688      0.0       0.0       0.0  ...   0.0       0.0  0.0  0.0  0.401813   \n",
       "4689      0.0  0.120958       0.0  ...   0.0       0.0  0.0  0.0       0.0   \n",
       "4690      0.0  0.298154       0.0  ...   0.0       0.0  0.0  0.0  0.104734   \n",
       "\n",
       "         watch   watched welcome yeah       yes  \n",
       "0          0.0       0.0     0.0  0.0       0.0  \n",
       "1          0.0       0.0     0.0  0.0       0.0  \n",
       "2          0.0       0.0     0.0  0.0       0.0  \n",
       "3     0.105414       0.0     0.0  0.0  0.149953  \n",
       "4     0.208594       0.0     0.0  0.0  0.131879  \n",
       "...        ...       ...     ...  ...       ...  \n",
       "4686       0.0       0.0     0.0  0.0  0.157521  \n",
       "4687  0.255874  0.383466     0.0  0.0       0.0  \n",
       "4688       0.0       0.0     0.0  0.0       0.0  \n",
       "4689  0.224337       0.0     0.0  0.0  0.106374  \n",
       "4690  0.207366       0.0     0.0  0.0  0.131103  \n",
       "\n",
       "[4691 rows x 71 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat, tfidf_columns = parser.get_tfidf_matrix(stop_words='english', min_df=0.2)\n",
    "\n",
    "# Construct dataset with id + summary word vectors\n",
    "cdata = np.concatenate((parser.dialog_df['movieid'].to_numpy().reshape(len(parser.dialog_df['summary']), 1), tfidf_mat), axis=1)\n",
    "df_mv_tfidf = pd.DataFrame(cdata, columns=['id'] + tfidf_columns.tolist())\n",
    "df_mv_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Metrics\n",
    "* Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the consine similarity function's denominator has 1e-7 minimum value to avoid the divbyzero.\n",
    "c_sim = lambda X, Y: np.dot(X, Y) / (1e-7 + norm(X) * norm(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation function\n",
    "* param:\n",
    "    * data: array, vector space of texts.\n",
    "    * mv: target movie's index\n",
    "    * length: maximum length of recommendation\n",
    "        * default: 5\n",
    "    * simf: consine similarity function\n",
    "        * default: dot(X, y) / (normalize(X) * normalize(Y) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(df, index, matrix, length=5, simf=c_sim):\n",
    "    sim = []\n",
    "\n",
    "    if df[df['movieid'] == str(index)].empty:\n",
    "        return sim\n",
    "\n",
    "    target = df[df['movieid'] == str(index)].index[0]\n",
    "\n",
    "    for idx, data in enumerate(matrix):\n",
    "        if idx != target:\n",
    "            sim.append([simf(data, matrix[target]), df.iloc[idx, 0]])\n",
    "    \n",
    "    sim.sort()\n",
    "    sim.reverse()\n",
    "    return sim[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>dialog</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>SentenceEmbedding</th>\n",
       "      <th>SimMatrix</th>\n",
       "      <th>score</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84779</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "      <td>[ Hi there, how are you?, I'm looking for movi...</td>\n",
       "      <td>[[hi], [looking, movie, recommendations, okay]...</td>\n",
       "      <td>[[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...</td>\n",
       "      <td>[[0.9999999403953552, 0.24245616793632507, 0.2...</td>\n",
       "      <td>{0: 0.06536974281629612, 1: 0.1115491066609117...</td>\n",
       "      <td>It is animated, sci fi, and has action Glad I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191602</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "      <td>[ Hi there, how are you?, I'm looking for movi...</td>\n",
       "      <td>[[hi], [looking, movie, recommendations, okay]...</td>\n",
       "      <td>[[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...</td>\n",
       "      <td>[[0.9999999403953552, 0.24245616793632507, 0.2...</td>\n",
       "      <td>{0: 0.06536974281629612, 1: 0.1115491066609117...</td>\n",
       "      <td>It is animated, sci fi, and has action Glad I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122159</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "      <td>[ Hi there, how are you?, I'm looking for movi...</td>\n",
       "      <td>[[hi], [looking, movie, recommendations, okay]...</td>\n",
       "      <td>[[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...</td>\n",
       "      <td>[[0.9999999403953552, 0.24245616793632507, 0.2...</td>\n",
       "      <td>{0: 0.06536974281629612, 1: 0.1115491066609117...</td>\n",
       "      <td>It is animated, sci fi, and has action Glad I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151313</td>\n",
       "      <td>Hi there, how are you? I'm looking for movie ...</td>\n",
       "      <td>[ Hi there, how are you?, I'm looking for movi...</td>\n",
       "      <td>[[hi], [looking, movie, recommendations, okay]...</td>\n",
       "      <td>[[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...</td>\n",
       "      <td>[[0.9999999403953552, 0.24245616793632507, 0.2...</td>\n",
       "      <td>{0: 0.005749033404559646, 1: 0.012240076161428...</td>\n",
       "      <td>Like  for example I like comedies but I prefer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>204322</td>\n",
       "      <td>Hi, did you see  ? Yes it was a pretty good m...</td>\n",
       "      <td>[ Hi, did you see  ?, Yes it was a pretty good...</td>\n",
       "      <td>[[hi, see], [yes, pretty, good, movie], [would...</td>\n",
       "      <td>[[-0.197045, 0.39572, 0.75997496, 0.09388, -0....</td>\n",
       "      <td>[[0.9999998807907104, 0.6657719016075134, 0.59...</td>\n",
       "      <td>{0: 0.032654807746370675, 1: 0.040617095075637...</td>\n",
       "      <td>Hello how are you, what are your favorite kind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>166377</td>\n",
       "      <td>Hi Hello there I LIKE SCI-FI genetic modifica...</td>\n",
       "      <td>[ Hi Hello there I LIKE SCI-FI genetic modific...</td>\n",
       "      <td>[[hi, hello, like, scifi, genetic, modificatio...</td>\n",
       "      <td>[[0.011004001, 0.2420111, 0.39807892, -0.12358...</td>\n",
       "      <td>[[1.0000001192092896, 0.6454883217811584, 0.66...</td>\n",
       "      <td>{0: 0.0692688154877309, 1: 0.06378854397892308...</td>\n",
       "      <td>You might would like  , which is a genetic mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>205981</td>\n",
       "      <td>What kind of movies do you like ? hello! I am...</td>\n",
       "      <td>[ What kind of movies do you like ?, hello!, I...</td>\n",
       "      <td>[[kind, movies, like], [hello], [looking, movi...</td>\n",
       "      <td>[[-0.030508334, 0.43740702, 0.4855567, -0.4959...</td>\n",
       "      <td>[[1.0, 0.3861870765686035, 0.8655173182487488,...</td>\n",
       "      <td>{0: 0.08503767938796901, 1: 0.0571018466271147...</td>\n",
       "      <td>It was a remake, or I guess a updated version ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>106113</td>\n",
       "      <td>hi HI, I like Sci-fi movies Genetic modificat...</td>\n",
       "      <td>[ hi HI, I like Sci-fi movies Genetic modifica...</td>\n",
       "      <td>[[hi, hi, like, scifi, movies, genetic, modifi...</td>\n",
       "      <td>[[0.06543327, 0.23472007, 0.48408842, 0.000198...</td>\n",
       "      <td>[[1.0, 0.7383857369422913, 0.8496346473693848,...</td>\n",
       "      <td>{0: 0.15428587521971038, 1: 0.1521021893291355...</td>\n",
       "      <td>Wow sounds good, haven't seen it guess i'll ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>96852</td>\n",
       "      <td>hi Hi !! have a good day which kind of movie ...</td>\n",
       "      <td>[ hi Hi !!, have a good day which kind of movi...</td>\n",
       "      <td>[[hi, hi], [good, day, kind, movie, like], [li...</td>\n",
       "      <td>[[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...</td>\n",
       "      <td>[[0.9999999403953552, 0.28580141067504883, 0.2...</td>\n",
       "      <td>{0: 0.07542525902780071, 1: 0.1299216272022606...</td>\n",
       "      <td>have a good day which kind of movie do you lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>200018</td>\n",
       "      <td>Hello! hi how can i help you So some of the m...</td>\n",
       "      <td>[ Hello!, hi how can i help you So some of the...</td>\n",
       "      <td>[[hello], [hi, help, movies, really, enjoy, th...</td>\n",
       "      <td>[[0.26688, 0.39632, 0.6169, -0.77451, -0.1039,...</td>\n",
       "      <td>[[0.9999999403953552, 0.37012484669685364, 0.3...</td>\n",
       "      <td>{0: 0.034745318070020716, 1: 0.060032179373261...</td>\n",
       "      <td>is one great example action packed movies wow!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4691 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieid                                             dialog  \\\n",
       "0      84779   Hi there, how are you? I'm looking for movie ...   \n",
       "1     191602   Hi there, how are you? I'm looking for movie ...   \n",
       "2     122159   Hi there, how are you? I'm looking for movie ...   \n",
       "4     151313   Hi there, how are you? I'm looking for movie ...   \n",
       "10    204322   Hi, did you see  ? Yes it was a pretty good m...   \n",
       "...      ...                                                ...   \n",
       "6217  166377   Hi Hello there I LIKE SCI-FI genetic modifica...   \n",
       "6218  205981   What kind of movies do you like ? hello! I am...   \n",
       "6219  106113   hi HI, I like Sci-fi movies Genetic modificat...   \n",
       "6220   96852   hi Hi !! have a good day which kind of movie ...   \n",
       "6221  200018   Hello! hi how can i help you So some of the m...   \n",
       "\n",
       "                                              sentences  \\\n",
       "0     [ Hi there, how are you?, I'm looking for movi...   \n",
       "1     [ Hi there, how are you?, I'm looking for movi...   \n",
       "2     [ Hi there, how are you?, I'm looking for movi...   \n",
       "4     [ Hi there, how are you?, I'm looking for movi...   \n",
       "10    [ Hi, did you see  ?, Yes it was a pretty good...   \n",
       "...                                                 ...   \n",
       "6217  [ Hi Hello there I LIKE SCI-FI genetic modific...   \n",
       "6218  [ What kind of movies do you like ?, hello!, I...   \n",
       "6219  [ hi HI, I like Sci-fi movies Genetic modifica...   \n",
       "6220  [ hi Hi !!, have a good day which kind of movi...   \n",
       "6221  [ Hello!, hi how can i help you So some of the...   \n",
       "\n",
       "                                    tokenized_sentences  \\\n",
       "0     [[hi], [looking, movie, recommendations, okay]...   \n",
       "1     [[hi], [looking, movie, recommendations, okay]...   \n",
       "2     [[hi], [looking, movie, recommendations, okay]...   \n",
       "4     [[hi], [looking, movie, recommendations, okay]...   \n",
       "10    [[hi, see], [yes, pretty, good, movie], [would...   \n",
       "...                                                 ...   \n",
       "6217  [[hi, hello, like, scifi, genetic, modificatio...   \n",
       "6218  [[kind, movies, like], [hello], [looking, movi...   \n",
       "6219  [[hi, hi, like, scifi, movies, genetic, modifi...   \n",
       "6220  [[hi, hi], [good, day, kind, movie, like], [li...   \n",
       "6221  [[hello], [hi, help, movies, really, enjoy, th...   \n",
       "\n",
       "                                      SentenceEmbedding  \\\n",
       "0     [[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...   \n",
       "1     [[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...   \n",
       "2     [[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...   \n",
       "4     [[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...   \n",
       "10    [[-0.197045, 0.39572, 0.75997496, 0.09388, -0....   \n",
       "...                                                 ...   \n",
       "6217  [[0.011004001, 0.2420111, 0.39807892, -0.12358...   \n",
       "6218  [[-0.030508334, 0.43740702, 0.4855567, -0.4959...   \n",
       "6219  [[0.06543327, 0.23472007, 0.48408842, 0.000198...   \n",
       "6220  [[0.1444, 0.23979, 0.96693, 0.31629, -0.36064,...   \n",
       "6221  [[0.26688, 0.39632, 0.6169, -0.77451, -0.1039,...   \n",
       "\n",
       "                                              SimMatrix  \\\n",
       "0     [[0.9999999403953552, 0.24245616793632507, 0.2...   \n",
       "1     [[0.9999999403953552, 0.24245616793632507, 0.2...   \n",
       "2     [[0.9999999403953552, 0.24245616793632507, 0.2...   \n",
       "4     [[0.9999999403953552, 0.24245616793632507, 0.2...   \n",
       "10    [[0.9999998807907104, 0.6657719016075134, 0.59...   \n",
       "...                                                 ...   \n",
       "6217  [[1.0000001192092896, 0.6454883217811584, 0.66...   \n",
       "6218  [[1.0, 0.3861870765686035, 0.8655173182487488,...   \n",
       "6219  [[1.0, 0.7383857369422913, 0.8496346473693848,...   \n",
       "6220  [[0.9999999403953552, 0.28580141067504883, 0.2...   \n",
       "6221  [[0.9999999403953552, 0.37012484669685364, 0.3...   \n",
       "\n",
       "                                                  score  \\\n",
       "0     {0: 0.06536974281629612, 1: 0.1115491066609117...   \n",
       "1     {0: 0.06536974281629612, 1: 0.1115491066609117...   \n",
       "2     {0: 0.06536974281629612, 1: 0.1115491066609117...   \n",
       "4     {0: 0.005749033404559646, 1: 0.012240076161428...   \n",
       "10    {0: 0.032654807746370675, 1: 0.040617095075637...   \n",
       "...                                                 ...   \n",
       "6217  {0: 0.0692688154877309, 1: 0.06378854397892308...   \n",
       "6218  {0: 0.08503767938796901, 1: 0.0571018466271147...   \n",
       "6219  {0: 0.15428587521971038, 1: 0.1521021893291355...   \n",
       "6220  {0: 0.07542525902780071, 1: 0.1299216272022606...   \n",
       "6221  {0: 0.034745318070020716, 1: 0.060032179373261...   \n",
       "\n",
       "                                                summary  \n",
       "0     It is animated, sci fi, and has action Glad I ...  \n",
       "1     It is animated, sci fi, and has action Glad I ...  \n",
       "2     It is animated, sci fi, and has action Glad I ...  \n",
       "4     Like  for example I like comedies but I prefer...  \n",
       "10    Hello how are you, what are your favorite kind...  \n",
       "...                                                 ...  \n",
       "6217  You might would like  , which is a genetic mod...  \n",
       "6218  It was a remake, or I guess a updated version ...  \n",
       "6219  Wow sounds good, haven't seen it guess i'll ha...  \n",
       "6220  have a good day which kind of movie do you lik...  \n",
       "6221  is one great example action packed movies wow!...  \n",
       "\n",
       "[4691 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.dialog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.dialog_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6217 is out of bounds for axis 0 with size 4691",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(recommend(parser\u001b[39m.\u001b[39;49mdialog_df, \u001b[39m166377\u001b[39;49m, tfidf_mat), columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mSimilarity\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMovie Index\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m df\n",
      "Cell \u001b[1;32mIn [13], line 11\u001b[0m, in \u001b[0;36mrecommend\u001b[1;34m(df, index, matrix, length, simf)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m idx, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(matrix):\n\u001b[0;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m idx \u001b[39m!=\u001b[39m target:\n\u001b[1;32m---> 11\u001b[0m         sim\u001b[39m.\u001b[39mappend([simf(data, matrix[target]), df\u001b[39m.\u001b[39miloc[idx, \u001b[39m0\u001b[39m]])\n\u001b[0;32m     13\u001b[0m sim\u001b[39m.\u001b[39msort()\n\u001b[0;32m     14\u001b[0m sim\u001b[39m.\u001b[39mreverse()\n",
      "\u001b[1;31mIndexError\u001b[0m: index 6217 is out of bounds for axis 0 with size 4691"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(recommend(parser.dialog_df, 166377, tfidf_mat), columns=['Similarity', 'Movie Index'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
